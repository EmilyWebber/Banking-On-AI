{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We treated those columns with a few unique values (less than 60) as categorical data. Originally, these data were not standardized in the data preprocessing step. This notebook is for standardization of categorical data with numerical dtypes. \n",
    "\n",
    "Note that these cat_num data also contain those columns which are in object dtype but with too many number of unique values. Those columns were encoded using label encoder and were combined with cat_num data, as the last three columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "#import seaborn as sns\n",
    "%matplotlib inline\n",
    "import requests\n",
    "#from pattern import web\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import cross_validation\n",
    "import gc\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from sklearn.base import TransformerMixin\n",
    "from datetime import datetime as dt\n",
    "from math import isnan\n",
    "from numpy import ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack,csr_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickledata/cat_numeric_th60_train2.dat','rb') as infile1:\n",
    "    cat_num_train = pickle.load(infile1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('pickledata/cat_numeric_th60_test2.dat','rb') as infile2:\n",
    "    cat_num_test = pickle.load(infile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145231, 244)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_num_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift feature values to positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ShiftPostive(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        shift selected numerical columns to positive value\n",
    "        \"\"\"\n",
    "        \n",
    "    def fit(self,X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def test_int(self,colvector):\n",
    "        \"\"\"\n",
    "        test if the float dtype columns have no non-integer values other than NA\n",
    "        input: column vector\n",
    "        output: boolean, True if the column has no non-integer value other than NA\n",
    "        \"\"\"\n",
    "        return colvector[colvector.notnull()].apply(lambda x:x.is_integer()).sum() == len(colvector[colvector.notnull()])\n",
    "\n",
    "    def transform(self,X,y=None, int_amount = 1, deci_amount = 0.1):\n",
    "        # separate out integer vs float-valued columns\n",
    "        int_cols = X.dtypes[X.dtypes == np.dtype('int64')].index.tolist()\n",
    "        int_cols2 = X.dtypes[X.dtypes == np.dtype('int32')].index.tolist()\n",
    "        int_cols  = int_cols + int_cols2\n",
    "        float_cols = X.dtypes[X.dtypes == np.dtype('float64')].index.tolist()\n",
    "        int_with_nans_bool = X[float_cols].apply(self.test_int)\n",
    "        int_with_nans = int_with_nans_bool[int_with_nans_bool].index.tolist()\n",
    "        int_cols.extend(int_with_nans)\n",
    "        float_cols = list(set(float_cols).difference(set(int_with_nans)))\n",
    "        # shift integer-valued columns and float valued columns separately\n",
    "        new_int_df = X[int_cols].apply(lambda x: x - x.min() + int_amount if x.min() <= 0 else x)\n",
    "        new_float_df = X[float_cols].apply(lambda x: x - x.min() + deci_amount if x.min() <= 0 else x)\n",
    "        return pd.merge(new_int_df,new_float_df,left_index=True,right_index=True),int_cols,float_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shiftpos = ShiftPostive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_num_train_shifted,int_cols1,float_cols1 = shiftpos.transform(cat_num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_num_test_shifted,int_cols2,float_cols2 = shiftpos.transform(cat_num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Log transform to highly right-skewed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogTransform(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        perform log transformation to columns that are uni-modal and right skewed\n",
    "        \"\"\"\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def normaltest(self,colvec,test = 'normal'):\n",
    "        \"\"\"\n",
    "        test if a column feature has normal distribution using the stats.mstats.normaltest, skewtest, or kurtosistest\n",
    "        notably, strong multi-modal data will have a masked value returned from kurtosis test, therefore can be filtered\n",
    "        after this function is called\n",
    "        input: colvec, column vector, in the format of pandas series\n",
    "                test: 'normal', 'skew','kurtosis'\n",
    "        output: \n",
    "            for normal:\n",
    "            k^2 + s^2, where k and s are the Z-score returned by the kurtosis test and the skew test\n",
    "            for a perfect normal distribution, k is 3 and s is zero\n",
    "            for skew or kurtosis:\n",
    "            z-score \n",
    "        \"\"\"\n",
    "        if test == 'normal':\n",
    "            return stats.mstats.normaltest(colvec[colvec.notnull()])[0]\n",
    "        elif test == 'skew':\n",
    "            return stats.mstats.skewtest(colvec[colvec.notnull()])[0]\n",
    "        elif test == 'kurtosis':\n",
    "            return stats.mstats.kurtosistest(colvec[colvec.notnull()])[0]\n",
    "        else:\n",
    "            print ('unknown test type')\n",
    "            return\n",
    "    \n",
    "    def transform(self,X,y=None,thresh = 5000):\n",
    "        #1. apply normal test and determine cols to transform\n",
    "        test_results = X.apply(self.normaltest)\n",
    "        multi_modal_cols = test_results[test_results.apply(lambda x: x is ma.masked)].index.tolist()\n",
    "        to_transform_cols = test_results[test_results > thresh].index.tolist()\n",
    "        #2. perform log transform\n",
    "        transformed_cols = X[to_transform_cols].apply(lambda x: np.log(x) if test_results[x.name] > thresh else x)\n",
    "        cols = X.columns.tolist()\n",
    "        unchanged_cols = list(set(cols).difference(set(to_transform_cols)))\n",
    "        return pd.merge(X[unchanged_cols],transformed_cols,right_index = True,left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logtrans = LogTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_num_train_shifted_log = logtrans.transform(cat_num_train_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_num_test_shifted_log = logtrans.transform(cat_num_test_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Standardize numerical data using standardscaler, first need to impute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_num_train_standard = scaler.fit_transform(cat_num_train_shifted_log.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_num_test_standard = scaler.fit_transform(cat_num_test_shifted_log.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145231L, 244L)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_num_train_standard.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Save processed data to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cat_numeric_th60_standard_train2.dat', 'wb') as cat_outfile1:\n",
    "    pickle.dump(cat_num_train_standard, cat_outfile1, protocol =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cat_numeric_th60_standard_test2.dat', 'wb') as cat_outfile2:\n",
    "    pickle.dump(cat_num_test_standard, cat_outfile2, protocol =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cat_numeric_th60_cols2.dat', 'wb') as cat_outfile3:\n",
    "    pickle.dump(cat_num_train_shifted_log.columns, cat_outfile3, protocol =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
