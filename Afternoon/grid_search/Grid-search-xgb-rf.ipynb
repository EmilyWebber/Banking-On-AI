{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from scipy import stats,sparse\n",
    "from sklearn.base import TransformerMixin\n",
    "from datetime import datetime as dt\n",
    "from math import isnan\n",
    "from numpy import ma\n",
    "import cPickle as pickle\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from pandas import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from re import sub\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold,cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XGBoostClassifier():\n",
    "    def __init__(self, num_boost_round=40, **params):\n",
    "        self.clf = None\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.params = params\n",
    "        self.params.update({'objective': 'binary:logistic'})\n",
    " \n",
    "    def fit(self, X, y, num_boost_round=None):\n",
    "        num_boost_round = num_boost_round or self.num_boost_round\n",
    "        dtrain = xgb.DMatrix(X.values, label=y)\n",
    "        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)\n",
    "        return self\n",
    " \n",
    "    def predict(self, X):\n",
    "        Y = self.predict_proba(X.values)\n",
    "        Y = np.argmax(Y, axis=1)\n",
    "        return Y\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        ypreds = np.zeros((X.shape[0],2))\n",
    "        dtest = xgb.DMatrix(X.values)\n",
    "        ypreds[:,1] = self.clf.predict(dtest)\n",
    "        ypreds[:,0] = 1- ypreds[:,1]        # return the proba for both classes\n",
    "        return ypreds\n",
    " \n",
    "    def score(self, X, y):\n",
    "        Y = self.predict_proba(X)\n",
    "        return 1 / self.logloss(y, Y)\n",
    " \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    " \n",
    "    def set_params(self, **params):\n",
    "        if 'objective' in params:\n",
    "            del params['objective']\n",
    "        self.params.update(params)\n",
    "        return self\n",
    "    \n",
    "    def logloss(self,y_true, Y_pred):\n",
    "        label2num = dict((name, i) for i, name in enumerate(sorted(set(y_true))))\n",
    "        return -1 * sum(math.log(y[label2num[label]]) if y[label2num[label]] > 0 else -np.inf for y, label in zip(Y_pred, y_true)) / len(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LocalTest=True           # whether to do a local test\n",
    "SelectedFeature=False    # whether to use selected features\n",
    "njobs = 1\n",
    "nrows=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if LocalTest:\n",
    "    trainfile = 'C:/Huaixiu/Kaggle/GridSearch/data/train-5000.csv'\n",
    "    xtrain = read_csv(trainfile,nrows=nrows)\n",
    "    ytrain = xtrain['target']\n",
    "    \n",
    "    xtrain = xtrain.ix[:,1:-1]\n",
    "\n",
    "else:    \n",
    "    X=np.load('data/nxtrain_standard_original0.npy')\n",
    "    X1= np.load('data/nxtrain_standard_derived0.npy')\n",
    "    X2=pickle.load(open(\"data/time_series_derived_train2.dat\",\"rb\"))\n",
    "    X3=pickle.load(open(\"data/time_series_original_train2.dat\",\"rb\"))\n",
    "    X4=pickle.load(open(\"data/cat_numeric_th60_train2.dat\",\"rb\"))\n",
    "    ytrain=pickle.load(open(\"data/ytrain2.dat\",\"rb\"))\n",
    "    xtrain=np.hstack((X,X1,X2,X3,X4))\n",
    "    del X,X1,X2,X3,X4\n",
    "    \n",
    "    if SelectedFeature:\n",
    "        with open('data/XGB_80Features Oct142015_221850_AUC_0p76183.p', 'rb') as fid:\n",
    "            xgb_goodfeat = pickle.load(fid)\n",
    "    \n",
    "        good_features=list(xgb_goodfeat)\n",
    "        xtrain = xtrain[:,good_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((5000, 1709), (5000L,))\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grid search: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if LocalTest:\n",
    "    param_xgb = {\n",
    "        'num_boost_round': [2],\n",
    "        'eta': [0.3],\n",
    "        'max_depth': [1],\n",
    "        'subsample': [0.9],\n",
    "        'colsample_bytree': [0.9],\n",
    "        'min_child_weight':[1],\n",
    "        'gamma':[10],\n",
    "        'objective':['binary:logistic'],\n",
    "        'eval_metric': ['auc']\n",
    "    }\n",
    "else:    \n",
    "    param_xgb = {\n",
    "        'num_boost_round': [40,100],\n",
    "        'eta': [0.01,0.1,0.3],\n",
    "        'max_depth': [6, 12],\n",
    "        'subsample': [1.0],\n",
    "        'colsample_bytree': [0.9, 1.0],\n",
    "        'min_child_weight':[1,3],\n",
    "        'gamma':[0,1],\n",
    "        'max_depth':[14],\n",
    "        'objective':['binary:logistic'],\n",
    "        'eval_metric': ['auc']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearch using XGBoost...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] colsample_bytree=0.9, eval_metric=auc, min_child_weight=1, subsample=0.9, eta=0.3, objective=binary:logistic, num_boost_round=2, max_depth=1, gamma=10 \n",
      "[CV]  colsample_bytree=0.9, eval_metric=auc, min_child_weight=1, subsample=0.9, eta=0.3, objective=binary:logistic, num_boost_round=2, max_depth=1, gamma=10 -   3.3s\n",
      "[CV] colsample_bytree=0.9, eval_metric=auc, min_child_weight=1, subsample=0.9, eta=0.3, objective=binary:logistic, num_boost_round=2, max_depth=1, gamma=10 \n",
      "[CV]  colsample_bytree=0.9, eval_metric=auc, min_child_weight=1, subsample=0.9, eta=0.3, objective=binary:logistic, num_boost_round=2, max_depth=1, gamma=10 -   3.9s\n",
      "[CV] colsample_bytree=0.9, eval_metric=auc, min_child_weight=1, subsample=0.9, eta=0.3, objective=binary:logistic, num_boost_round=2, max_depth=1, gamma=10 \n",
      "[CV]  colsample_bytree=0.9, eval_metric=auc, min_child_weight=1, subsample=0.9, eta=0.3, objective=binary:logistic, num_boost_round=2, max_depth=1, gamma=10 -   3.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed GridSearch using XGBoost\n",
      "Total running time is 16 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time=time.clock()\n",
    "\n",
    "print('Starting GridSearch using XGBoost...')\n",
    "clf_xgb = XGBoostClassifier()\n",
    "gs_xgb = GridSearchCV(clf_xgb,param_grid = param_xgb,cv = StratifiedKFold(ytrain,n_folds = 3),scoring='roc_auc', n_jobs = njobs,verbose = 2)\n",
    "gs_xgb.fit(xtrain,ytrain)\n",
    "\n",
    "total_time=time.clock()-start_time\n",
    "print('Completed GridSearch using XGBoost')\n",
    "print('Total running time is %d seconds\\n' %total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC Score of XGB is 1.0\n",
      "Best parameters set of XGB:\n",
      "\tcolsample_bytree: 0.9\n",
      "\teta: 0.3\n",
      "\teval_metric: 'auc'\n",
      "\tgamma: 10\n",
      "\tmax_depth: 1\n",
      "\tmin_child_weight: 1\n",
      "\tnum_boost_round: 2\n",
      "\tobjective: 'binary:logistic'\n",
      "\tsubsample: 0.9\n"
     ]
    }
   ],
   "source": [
    "print 'Best AUC Score of XGB is {}'.format(gs_xgb.best_score_)\n",
    "print 'Best parameters set of XGB:'\n",
    "best_param_xgb = gs_xgb.best_estimator_.get_params()\n",
    "for param_name in sorted(best_param_xgb.keys()):\n",
    "    print '\\t%s: %r' % (param_name,best_param_xgb[param_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###dump the model to pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_opt = gs_xgb.best_estimator_\n",
    "\n",
    "with open('xgb_opt.pkl', 'wb') as fid:\n",
    "    pickle.dump(xgb_opt, fid,protocol = 2)\n",
    "    \n",
    "with open('xgb_best_param.pkl', 'wb') as fid:\n",
    "    pickle.dump(best_param_xgb, fid,protocol = 2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9,\n",
       " 'eta': 0.3,\n",
       " 'eval_metric': 'auc',\n",
       " 'gamma': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'num_boost_round': 10,\n",
       " 'objective': 'binary:logistic',\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestparam=pickle.load(open(\"xgb_best_param.pkl\",\"rb\"))\n",
    "bestparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2. GridSearch using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if LocalTest:\n",
    "    param_rf = {'n_estimators': [200],'max_depth':[20],'n_jobs': [1],'max_features':['auto'],'min_samples_leaf':[1,3]}        \n",
    "else:    \n",
    "    param_rf = {'n_estimators': [200,500],\n",
    "            'max_depth':[20,None],\n",
    "         'n_jobs': [-1],\n",
    "         'max_features':['auto'],\n",
    "        'min_samples_leaf':[1,3,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearch using RandomForest...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=1 \n",
      "[CV]  max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=1 -  12.0s\n",
      "[CV] max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=1 \n",
      "[CV]  max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=1 -  18.8s\n",
      "[CV] max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=1 \n",
      "[CV]  max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=1 -  15.1s\n",
      "[CV] max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=3 \n",
      "[CV]  max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=3 -  17.1s\n",
      "[CV] max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=3 \n",
      "[CV]  max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=3 -  16.9s\n",
      "[CV] max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=3 \n",
      "[CV]  max_features=auto, n_estimators=200, n_jobs=1, max_depth=20, min_samples_leaf=3 -  16.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:   12.1s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed GridSearch using RandomForest\n",
      "Total running time is 131 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time=time.clock()\n",
    "\n",
    "print('Starting GridSearch using RandomForest...')\n",
    "clf_rf = RandomForestClassifier(random_state =100)\n",
    "gs_rf = GridSearchCV(clf_rf,param_grid = param_rf,cv = StratifiedKFold(ytrain,n_folds = 3),scoring='roc_auc', n_jobs = njobs,verbose = 2)\n",
    "gs_rf.fit(xtrain,ytrain)\n",
    "\n",
    "total_time=time.clock()-start_time\n",
    "print('Completed GridSearch using RandomForest')\n",
    "print('Total running time is %d seconds\\n' %total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC Score of RF is 0.994065966861\n",
      "Best parameters set of RF:\n",
      "\tbootstrap: True\n",
      "\tclass_weight: None\n",
      "\tcriterion: 'gini'\n",
      "\tmax_depth: 20\n",
      "\tmax_features: 'auto'\n",
      "\tmax_leaf_nodes: None\n",
      "\tmin_samples_leaf: 1\n",
      "\tmin_samples_split: 2\n",
      "\tmin_weight_fraction_leaf: 0.0\n",
      "\tn_estimators: 200\n",
      "\tn_jobs: 1\n",
      "\toob_score: False\n",
      "\trandom_state: 100\n",
      "\tverbose: 0\n",
      "\twarm_start: False\n"
     ]
    }
   ],
   "source": [
    "print 'Best AUC Score of RF is {}'.format(gs_rf.best_score_)\n",
    "print 'Best parameters set of RF:'\n",
    "best_param_rf = gs_rf.best_estimator_.get_params()\n",
    "for param_name in sorted(best_param_rf.keys()):\n",
    "    print '\\t%s: %r' % (param_name,best_param_rf[param_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###dump the model into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_opt = gs_rf.best_estimator_\n",
    "\n",
    "with open('rf_opt.pkl', 'wb') as fid:\n",
    "    pickle.dump(rf_opt, fid,protocol = 2)\n",
    "    \n",
    "with open('rf_best_param.pkl', 'wb') as fid:\n",
    "    pickle.dump(best_param_rf, fid,protocol = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 200,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 100,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestparam=pickle.load(open(\"rf_best_param.pkl\",\"rb\"))\n",
    "bestparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3. make prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf0 = XGBoostClassifier()\n",
    "clf0.set_params(**best_param_xgb)\n",
    "XGB = clf0.fit(xtrain,ytrain)\n",
    "\n",
    "\n",
    "clf1 = RandomForestClassifier(random_state =100)\n",
    "clf1.set_params(**best_param_rf)\n",
    "RF = clf1.fit(xtrain,ytrain)\n",
    "\n",
    "del xtrain\n",
    "del ytrain\n",
    "\n",
    "with open('data/xtest_ID.pkl','rb') as fid:\n",
    "    test_ID = pickle.load(fid)\n",
    "\n",
    "    # load test data set\n",
    "if LocalTest:\n",
    "    testfile = 'C:/Huaixiu/Kaggle/GridSearch/data/train-5000.csv'\n",
    "    xtest = read_csv(testfile,nrows=nrows)\n",
    "    xtest = xtest.ix[:,1:-1]\n",
    "    \n",
    "    test_ID = test_ID[:nrows]\n",
    "    \n",
    "else:    \n",
    "    X=np.load('data/nxtest_standard_original0.npy')\n",
    "    X1= np.load('data/nxtest_standard_derived0.npy')\n",
    "    X2=pickle.load(open(\"data/time_series_derived_test2.dat\",\"rb\"))\n",
    "    X3=pickle.load(open(\"data/time_series_original_test2.dat\",\"rb\"))\n",
    "    X4=pickle.load(open(\"data/cat_numeric_th60_test2.dat\",\"rb\"))\n",
    "    xtest=np.hstack((X,X1,X2,X3,X4))\n",
    "    del X,X1,X2,X3,X4\n",
    "    \n",
    "    \n",
    "    if SelectedFeature:\n",
    "        with open('data/XGB_75Features Oct142015_171619_AUC_0p76030.p', 'rb') as fid:\n",
    "            xgb_goodfeat = pickle.load(fid)\n",
    "    \n",
    "        good_features=list(xgb_goodfeat)\n",
    "        xtest = xtest[:,good_features]\n",
    "\n",
    "# make final predictions\n",
    "ypreds_xgb = XGB.predict_proba(xtest)[:,1]\n",
    "ypreds_rf = RF.predict_proba(xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ypreds_xgb_gs_basic.pkl', 'wb') as fid:\n",
    "    pickle.dump(ypreds_xgb, fid,protocol = 2)\n",
    "    \n",
    "with open('ypreds_rf_gs_basic.pkl', 'wb') as fid:\n",
    "    pickle.dump(ypreds_rf, fid,protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate submission files\n",
    "\n",
    "def save_results(test_ID, predictions, filename):\n",
    "    \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"ID,target\\n\")\n",
    "        for i in range(len(test_ID)):\n",
    "            f.write(\"%d,%f\\n\" % (test_ID[i], predictions[i]))\n",
    "    \n",
    "save_results(test_ID, ypreds_xgb, 'ypreds_xgb_gs_basic.csv')\n",
    "save_results(test_ID, ypreds_rf, 'ypreds_rf_gs_basic.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
