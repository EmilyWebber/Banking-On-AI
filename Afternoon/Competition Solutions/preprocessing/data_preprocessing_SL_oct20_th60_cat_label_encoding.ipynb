{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for label encoding the categorical features in obj format, for easier feature selection.\n",
    "\n",
    "Those categorical features with number of unique values larger than 60 (3 features in total including the city names feature) have already label encoded and contained in the cat_numeric_th60 data. \n",
    "\n",
    "Here we only need to label encode the originally one-hot encoded features. After these features are selected by XGBoost, they can be re-encoded using OHE. For those labels which never appear in training data but only appear in test data, they are set to nan. All the nans are treated as one type, NA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "#import seaborn as sns\n",
    "%matplotlib inline\n",
    "import requests\n",
    "#from pattern import web\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import cross_validation\n",
    "import gc\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from sklearn.base import TransformerMixin\n",
    "from datetime import datetime as dt\n",
    "from math import isnan\n",
    "from numpy import ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack,csr_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "na_values = ['[]','',-1]\n",
    "train = pd.read_csv('./train.csv',na_values = na_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\python2\\lib\\site-packages\\pandas\\io\\parsers.py:1170: DtypeWarning: Columns (8,9,10,11,12,43,157,167,177,196,214,225,228,229,231,235,238) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./test.csv',na_values = na_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mixed_col_num = [8,9,10,11,12,43,157,196,214,225,228,229,231,235,238]\n",
    "mixed_cols = [cols[i] for i in mixed_col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain = train.drop(['target','ID'],axis = 1)\n",
    "indices_train = xtrain.index #to be used later for separating train and test data parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest = test.drop(['ID'],axis = 1)\n",
    "#shift the index of test data before concat\n",
    "indices_test = xtest.index\n",
    "indices_test = indices_test + xtrain.shape[0] \n",
    "xtest.index = indices_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#release memory\n",
    "%xdel train\n",
    "%xdel test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtotal = pd.concat([xtrain, xtest])\n",
    "indices_total = xtotal.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145231, 1932)\n",
      "(290463, 1932)\n"
     ]
    }
   ],
   "source": [
    "%xdel xtest\n",
    "print (xtrain.shape)\n",
    "print (xtotal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pre-processing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropNA = True       #drop columns with NAs > than dropNAThresh. This will also change the behavior of dropconstant_col.\n",
    "dropNAThresh = 0.98 #percentage\n",
    "\n",
    "separate_cat_num_thresh = 1 #treat those numerical variables with less than th unique values as categorical\n",
    "\n",
    "dropNA_time= True\n",
    "dropNAThresh_time = 0.75 #for time and dates\n",
    "\n",
    "dropNA_cat = False #perform additional nan dropping to categorical data\n",
    "dropNAThresh_cat = 0.75 #for categorical data\n",
    "\n",
    "outlierThresh = 5\n",
    "outlierUniqueThresh = 20 #if number of unique values in a column is less than this threshold, do not apply outlier removal.\n",
    "remove_personal_income_outlier = False #do not remove outlier in personal income\n",
    "\n",
    "fillNAStrategy_numeric= 'mean' # 'mode', 'median', 'mean', or number\n",
    "fillNAStrategy_time = 'median'#strategy for filling missing values in the original time variables\n",
    "fillNAStrategy_time_derived = 'mode'#strategy for filling missing values in the derived time variables\n",
    "fillNAStrategy_cat_num = 'mode' #strategy for filling missing values in categorical variables which are numeric type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_cols = set(['VAR_0073','VAR_0075','VAR_0156','VAR_0157',\n",
    "           'VAR_0158','VAR_0159','VAR_0166','VAR_0167','VAR_0168','VAR_0169',\n",
    "           'VAR_0176','VAR_0177','VAR_0178','VAR_0179','VAR_0204','VAR_0217','VAR_0314','VAR_0531']).intersection(set(xtotal.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_cols = list(time_cols)\n",
    "time_cols.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataFrameSep(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        separate numerical and categorical feature columns \n",
    "        the transform returns two dataframes, one for each\n",
    "        \"\"\"\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X, y=None,thresh = 10, dropna = True):\n",
    "        \"\"\"\n",
    "        this function separates the numerical and non-numerical columns, output two lists of column names\n",
    "        input:  X, feature dataframe\n",
    "                thresh, number of unique values such that if a column has no more than this number of unique values,\n",
    "                it is treated as categorical even if the dtype is numerical\n",
    "                dropna, if False, nan is counted as an unique value when compare # of unique values with the thresh\n",
    "        output: cX: dataframe of categorical features\n",
    "                nX: dataframe of numerical features\n",
    "\n",
    "        \"\"\"\n",
    "        cat = X.dtypes == 'object'\n",
    "        cat_cols = X.dtypes[cat].index.tolist()\n",
    "        raw_num_cols = X.dtypes[~cat].index.tolist()\n",
    "        num_unique = X[raw_num_cols].apply(lambda x: x.nunique(dropna = dropna),axis = 0)\n",
    "        convert_to_cat_cols = num_unique[num_unique < thresh].index.tolist()\n",
    "        cat_cols.extend(convert_to_cat_cols)\n",
    "        num_cols = [x for x in raw_num_cols if x not in convert_to_cat_cols]\n",
    "#         cX,nX = X[cat_cols],X[num_cols]\n",
    "        return cat_cols,num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep = DataFrameSep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# non_ts_col: non time series columns\n",
    "non_ts_col = list(set(xtotal.columns).difference(set(time_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cxtotal_cols,nxtotal_cols = sep.transform(xtotal[non_ts_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 429 qualitative features and 1485 quantitative features\n"
     ]
    }
   ],
   "source": [
    "print ('There are {} qualitative features and {} quantitative features'.format(len(cxtotal_cols),len(nxtotal_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cxtotal = xtotal[cxtotal_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel xtotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290463, 429)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxtotal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.Filter columns based on number of missing values and unique values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFrameFilter(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Filter feature columns based on nan values and/or constant values\n",
    "        To transform, target must be specified as either \"nan\" or \"constant\"\n",
    "        \n",
    "        \"\"\"\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None, target = 'nan',thresh = 0.98):\n",
    "        \"\"\"\n",
    "        X is the feature dataframe, target can be \"nan\" or \"constant\", \n",
    "        thresh is the fraction of nans or the constant value that justifies the \n",
    "        feature column to be filtered\n",
    "        \"\"\"\n",
    "        if target != 'nan' and target != 'constant':\n",
    "            raise KeyError('Invalid target, valide targets are nan and constant')\n",
    "        elif target == 'nan':\n",
    "            num_nan = X.isnull().sum()\n",
    "            perc_nan = num_nan.apply(lambda x: float(x)/(X.shape[0]))\n",
    "            return X.drop([x for x in perc_nan.index if perc_nan[x] > thresh],axis = 1)\n",
    "        else:\n",
    "            const_fraction = X.apply(lambda x: x.value_counts(normalize=True,dropna = False).values[0])\n",
    "            kept_cols = const_fraction[const_fraction < thresh].index.tolist()\n",
    "            return X[kept_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dffilter = DataFrameFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if dropNA:\n",
    "#     cxtrain = dffilter.transform(cxtrain)\n",
    "    cxtotal = dffilter.transform(cxtotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290463, 421)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxtotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cxtotal = dffilter.transform(cxtotal,target = 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290463, 259)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxtotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check to see if there is any constant columns in train data\n",
    "cxtrain = cxtotal.iloc[:len(indices_train),:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = cxtrain.apply(lambda x: len(x.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'VAR_0466'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt[tt==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1      I\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "Name: VAR_0466, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxtrain['VAR_0466'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3. Separate numerical vs categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 259 qualitative features and 1448 quantitative features\n"
     ]
    }
   ],
   "source": [
    "print ('There were 259 qualitative features and 1448 quantitative features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4. Categorical features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### categorical columns divide into two types, obj-type columns and ordinal(numerical)-type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290463, 259)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxtotal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def consolidate(strings_input):\n",
    "    \"\"\"\n",
    "    Transform in-place the given dataset by consolidating\n",
    "    rare categorical features into a single category.\n",
    "    \"\"\"\n",
    "    strings_consolidate = strings_input.copy()\n",
    "    strings_value_counts =  strings_input.value_counts()\n",
    "    rare_strings = strings_value_counts[strings_value_counts==1].index\n",
    "    for i in rare_strings:\n",
    "        strings_consolidate[strings_input==i]='rare_string'\n",
    "    return strings_consolidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####First, object-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj_cols = cxtotal.dtypes[cxtotal.dtypes == 'object'].index.tolist()\n",
    "num_cat_cols = cxtotal.dtypes[cxtotal.dtypes != 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('obj_cols.p', 'wb') as cat_outfile_obj_cols:\n",
    "    pickle.dump(obj_cols, cat_outfile_obj_cols, protocol =2)\n",
    "with open('num_cat_cols.p', 'wb') as cat_outfile_num_cat_cols:\n",
    "    pickle.dump(num_cat_cols, cat_outfile_num_cat_cols, protocol =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cxtotal_obj = cxtotal[obj_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290463, 18)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxtotal_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16582\n",
      "9618\n"
     ]
    }
   ],
   "source": [
    "#consolidate VAR_0200: city names\n",
    "print (len(cxtotal_obj['VAR_0200'].value_counts()))\n",
    "temp1 = cxtotal_obj['VAR_0200'].copy()    \n",
    "temp2 = consolidate(temp1)\n",
    "cxtotal_obj['VAR_0200'] = temp2 \n",
    "print (len(cxtotal_obj['VAR_0200'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#separate those with unique values less than 60\n",
    "cxtotal_obj_value_counts = cxtotal_obj.apply(lambda x: x.nunique(dropna = False))\n",
    "cat_uq_thresh = 60\n",
    "obj_cols_final = cxtotal_obj_value_counts[cxtotal_obj_value_counts < cat_uq_thresh].index.tolist()\n",
    "other_cols = list(set(cxtotal_obj.columns).difference(set(obj_cols_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VAR_0200', 'VAR_0493', 'VAR_0404']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cxtotal_obj = cxtotal_obj.drop(other_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290463, 15)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxtotal_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cxtrain_obj = cxtotal_obj.iloc[:len(indices_train),:].copy()\n",
    "cxtest_obj = cxtotal_obj.iloc[len(indices_train):,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set those test data to nan if the label was not found in train data\n",
    "no_label_counts = np.zeros(cxtotal_obj.shape[1])\n",
    "for c in range(cxtotal_obj.shape[1]):\n",
    "    temp_train_values = cxtrain_obj.iloc[:,c].copy()\n",
    "    temp_test_values = cxtest_obj.iloc[:,c].copy()\n",
    "    temp_notnull_ind = temp_test_values[temp_test_values.notnull()].index\n",
    "    for ii in temp_notnull_ind:\n",
    "        if temp_test_values[ii] not in temp_train_values:\n",
    "            temp_test_values[ii] = np.nan #remove that label\n",
    "            no_label_counts[c]=no_label_counts[c]+1\n",
    "    #update the test data\n",
    "    cxtest_obj.iloc[:,c] = temp_test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  22818.,   22592.,  145184.,       0.,  145232.,  139416.,\n",
       "        120458.,  141801.,  138318.,  112829.,  130739.,  145232.,\n",
       "        145232.,  141433.,  143968.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290463, 15)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update cxtotal_obj\n",
    "cxtotal_obj = pd.concat([cxtrain_obj, cxtest_obj])\n",
    "cxtotal_obj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cxtotal_obj = cxtotal_obj.fillna('NA') #fill NaN with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#label encode all the cols\n",
    "le = LabelEncoder()\n",
    "for c in cxtotal_obj.columns:\n",
    "    cxtotal_obj[c]=le.fit_transform(cxtotal_obj[c].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR_0466</th>\n",
       "      <th>VAR_0467</th>\n",
       "      <th>VAR_0237</th>\n",
       "      <th>VAR_0232</th>\n",
       "      <th>VAR_1934</th>\n",
       "      <th>VAR_0283</th>\n",
       "      <th>VAR_0354</th>\n",
       "      <th>VAR_0352</th>\n",
       "      <th>VAR_0353</th>\n",
       "      <th>VAR_0342</th>\n",
       "      <th>VAR_0325</th>\n",
       "      <th>VAR_0005</th>\n",
       "      <th>VAR_0001</th>\n",
       "      <th>VAR_0305</th>\n",
       "      <th>VAR_0274</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAR_0466  VAR_0467  VAR_0237  VAR_0232  VAR_1934  VAR_0283  VAR_0354  \\\n",
       "0         1         3         9         2         2         5         1   \n",
       "1         0         1         4         0         2         5         2   \n",
       "2         1         3        44         2         2         5         0   \n",
       "3         1         3        39         0         5         5         0   \n",
       "4         1         3        14         2         0         5         1   \n",
       "\n",
       "   VAR_0352  VAR_0353  VAR_0342  VAR_0325  VAR_0005  VAR_0001  VAR_0305  \\\n",
       "0         1         3        19         4         1         0         6   \n",
       "1         1         2        30         2         0         0         6   \n",
       "2         2         2        49         6         1         0         4   \n",
       "3         2         2        42         2         1         0         4   \n",
       "4         2         3        42         7         2         3         4   \n",
       "\n",
       "   VAR_0274  \n",
       "0        10  \n",
       "1        24  \n",
       "2        55  \n",
       "3        49  \n",
       "4        16  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxtotal_obj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Save processed data to disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145231, 15)\n",
      "(145232, 15)\n"
     ]
    }
   ],
   "source": [
    "#separate train and test sparse matrices\n",
    "cxtrain_le = cxtotal_obj.iloc[:len(indices_train), :]\n",
    "cxtest_le = cxtotal_obj.iloc[len(indices_train):, :]\n",
    "print (cxtrain_le.shape)\n",
    "print (cxtest_le.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cat_le_train2.dat', 'wb') as cat_outfile1:\n",
    "    pickle.dump(cxtrain_le, cat_outfile1, protocol =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cat_le_test2.dat', 'wb') as cat_outfile2:\n",
    "    pickle.dump(cxtest_le, cat_outfile2, protocol =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
