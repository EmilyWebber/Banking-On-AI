{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import hinge_loss\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "from scipy.sparse import hstack,csr_matrix\n",
    "import cPickle as pickle\n",
    "import random\n",
    "# xgBoost AUC: 0.76833777818980442\n",
    "# RF AUC: 0.75744520850500441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=np.load('./pickledata/nxtrain_standard_original0.npy')\n",
    "X1= np.load('./pickledata/nxtrain_standard_derived0.npy')\n",
    "X2=pickle.load(open(\"./pickledata/time_series_derived_standard_train2.dat\",\"rb\"))\n",
    "X3=pickle.load(open(\"./pickledata/time_series_original_standard_train2.dat\",\"rb\"))\n",
    "X4=pickle.load(open(\"./pickledata/cat_numeric_th60_standard_train2.dat\",\"rb\"))\n",
    "X5=pickle.load(open(\"./pickledata/cat_le_train2.dat\",\"rb\"))#label encoded categorical data 15 in total\n",
    "y=pickle.load(open(\"./pickledata/ytrain2.dat\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=np.hstack((X,X1,X2,X3,X4,X5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr):\n",
    "    \"\"\"Plot ROC curve and display it.\"\"\"\n",
    "    plt.clf()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.savefig('plots/ROC_curve.png')\n",
    "\n",
    "    \n",
    "def learning_curve(model, X_train, y_train, X_cv, y_cv,n=20):\n",
    "    \"\"\"Plot train and cv loss for increasing train sample sizes.\"\"\"\n",
    "    chunk = int(len(y)/n)\n",
    "    n_samples = []\n",
    "    train_losses = []\n",
    "    cv_losses = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        train_subset = X_train[:(i + 1)*chunk]\n",
    "        MD = model.fit(X_train[:(i + 1)*chunk], y_train[:(i + 1)*chunk])\n",
    "        \n",
    "        preds_train = model.predict_proba(X_train[:(i + 1)*chunk])\n",
    "        preds_cv = model.predict_proba(X_cv)\n",
    "        \n",
    "        n_samples.append((i + 1)*chunk)\n",
    "        cv_losses.append(hinge_loss(y_cv, preds_cv, labels=0))\n",
    "        train_losses.append(hinge_loss(y_train[:(i + 1)*chunk], preds_train, labels=0))\n",
    "\n",
    "    plt.gca()\n",
    "    plt.plot(n_samples, train_losses, 'r--', n_samples, cv_losses, 'b--')\n",
    "    plt.gca()\n",
    "    plt.plot(n_samples, train_losses,'ro--',label='train_loss')\n",
    "    plt.plot(n_samples, cv_losses, 'bd--',label='cv_loss')\n",
    "    plt.legend(loc='best',fontsize='medium')\n",
    "    plt.xlabel('sample size')\n",
    "    plt.ylabel('hinge loss')\n",
    "    plt.ylim([min(train_losses) - .01, max(cv_losses) + .01])\n",
    "\n",
    "    plt.savefig('plots/learning_curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "def cv_loop(X, y, model, N, SEED=40, diagnostics=False, randomsplit=False):   # N random splits into train and test sets with the test of 1/N fraction\n",
    "    # Return the ((mean and std of the cv AUC score), and fscore)\n",
    "    AUC = np.zeros(N) \n",
    "    if N ==1:\n",
    "        skf = cross_validation.StratifiedKFold(y, n_folds=2) # K-fold cv splitting\n",
    "        if len(X.shape)==1:#to be compatible with forward selection\n",
    "            fscore_total = 0\n",
    "        else:\n",
    "            fscore_total = np.zeros((X.shape[1],2)) #feature num * 2\n",
    "    else:# N >=2 folds\n",
    "        skf = cross_validation.StratifiedKFold(y, n_folds=N) # K-fold cv splitting\n",
    "        if len(X.shape)==1:#to be compatible with forward selection\n",
    "            fscore_total = 0\n",
    "        else:\n",
    "            fscore_total = np.zeros((X.shape[1],N)) #feature num * N-fold cv\n",
    "\n",
    "    i=0\n",
    "    for train, cv in skf:\n",
    "        if randomsplit: # random split of the row index\n",
    "            train, cv = cross_validation.train_test_split(range(len(y)), test_size=1.0/float(N), random_state = i*SEED)\n",
    "            \n",
    "        if len(X.shape)==1:\n",
    "            MODEL = model.fit(X[train], y[train])\n",
    "            preds_cv = model.predict_proba(X[cv])\n",
    "        else:\n",
    "            MODEL = model.fit(X[train,:], y[train])\n",
    "            preds_cv = model.predict_proba(X[cv,:])\n",
    "            fscore_cv = model.fscore #raw fscore dictionary eg ['f100':1]\n",
    "            fscore_list =[[int(ftemp[1:]), vtemp] for ftemp, vtemp in fscore_cv.iteritems()]\n",
    "            fscore_list.sort(key=lambda fv:fv[0])#sort based on the feature names(indices)\n",
    "            #some features have no fscore, assumed to be 0\n",
    "            fscore_features = [fscore_list_temp[0] for fscore_list_temp in fscore_list]\n",
    "            fscore_values =   [fscore_list_temp[1] for fscore_list_temp in fscore_list]\n",
    "            fscore_total[fscore_features,i] = fscore_values#fill in for the i-th fold\n",
    "        \n",
    "        fpr, tpr, _ = metrics.roc_curve(y[cv], preds_cv)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "        AUC[i] = roc_auc\n",
    "\n",
    "        # plot learning curve and roc curve for diagonistics purpose\n",
    "        if diagnostics and i == 0:  # only plot for first fold\n",
    "            print(\"plotting ROC curve\")\n",
    "            plot_roc(fpr, tpr)\n",
    "            print(\"plotting learning curve\")\n",
    "            if len(X.shape)==1:\n",
    "                learning_curve(model, X[train], y[train], X[cv,:], y[cv])\n",
    "            else:\n",
    "                learning_curve(model, X[train,:], y[train], X[cv,:], y[cv])\n",
    "        i+=1\n",
    "        if N==1: #for N=1, since minimum N should be 2 in StratifiedKFold\n",
    "            #duplicate the fscore\n",
    "            fscore_total[:,1]=fscore_total[:,0]\n",
    "            mean_auc = AUC\n",
    "            std_auc = 0\n",
    "            break\n",
    "    if N>1:\n",
    "        mean_auc = AUC.mean()\n",
    "        std_auc = AUC.std()\n",
    "        \n",
    "    if len(X.shape)==1:\n",
    "        fscore = 0\n",
    "    else:\n",
    "        fscore = fscore_total.mean(axis=1)\n",
    "    \n",
    "    return ((mean_auc, std_auc), fscore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_selection_backward(model, params, Xtrain, ytrain, diagonistics=False, SEED=42, num_rows=10000, drop_features_percent=0.1, feature_num_thresh=10, n_cv_rounds = 2, auc_prec=10000,auc_prec2=10000):\n",
    "    \"Backward feature selection using feature importance in xgboost\"\n",
    "\n",
    "    print \"Performing backward feature selection...\"\n",
    "    score_hist = []\n",
    "    total_features = np.asarray(range(Xtrain.shape[1])) #all the columns, fixed column numbers for all the features\n",
    "    good_features = total_features #column of the features in the original matrix\n",
    "    use_features = total_features[good_features]#the column being used\n",
    "    userows_hist=[]#check random number generator\n",
    "    \n",
    "    MODEL = model.set_params(random_state=SEED)\n",
    "    MODEL.set_params(params=params)\n",
    "    \n",
    "    bestAUC=0\n",
    "    \n",
    "    while len(good_features)>=feature_num_thresh: #stop when there are feature_num_thresh features left \n",
    "        scores = []    \n",
    "        if num_rows < Xtrain.shape[0]:\n",
    "            #random sampling for stochastic feature selection\n",
    "            userows = sorted(random.sample(range(Xtrain.shape[0]), num_rows))\n",
    "        else:\n",
    "            #use all the rows\n",
    "            userows = range(Xtrain.shape[0])     \n",
    "        if userows == userows_hist and num_rows < Xtrain.shape[0]:\n",
    "            userows = sorted(random.sample(range(Xtrain.shape[0]), num_rows))\n",
    "            print('Two randomly chosen lists appeared to be the same')\n",
    "        userows_hist = userows\n",
    "        \n",
    "        #get the fscore of all the features using a cv_loop\n",
    "        score, fscore_temp = cv_loop(Xtrain[userows, :][:,use_features], ytrain[userows], MODEL, N=n_cv_rounds)\n",
    "        \n",
    "        if round(score[0] * auc_prec) >= round(bestAUC * auc_prec):\n",
    "            bestAUC = score[0]\n",
    "            score_hist.append(bestAUC) \n",
    "            print('\\t\\t\\t\\t %d features left. Current AUC: %f' % ( len(good_features), bestAUC))\n",
    "            #save results\n",
    "            str1=time.strftime(\"%b%d%Y_%H%M%S\", time.localtime())\n",
    "            with open(('XGBoost_backward_selection_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f:\n",
    "                pickle.dump(use_features, f, protocol =2)\n",
    "            with open(('fscores_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f2:\n",
    "                pickle.dump(fscore_temp, f2, protocol =2)\n",
    "            \n",
    "            #drop redundant features\n",
    "            #fscore_temp is an array corresponding to the fscores of the good features being used.\n",
    "            fscore_sorted_index = np.argsort(fscore_temp)[::-1]         \n",
    "            good_feature_rows = int(len(fscore_sorted_index) * (1- drop_features_percent))#how many rows to keep\n",
    "            \n",
    "            good_features = fscore_sorted_index[0:good_feature_rows]#index in the current use_feature\n",
    "            other_features  = fscore_sorted_index[good_feature_rows:]#index in the current use_feature\n",
    "            #update hist_features first, since use_features itself will be updated shortly\n",
    "            hist_features = use_features[other_features]#use_features contain the indices in the total_features\n",
    "            #update use_features, to be used in next loop\n",
    "            use_features  = use_features[good_features] #use_features contain the indices in the total_features\n",
    "        else:\n",
    "            #score is not better than the last bestAUC\n",
    "            #recover the dropped features one by one till the AUC is >= bestAUC\n",
    "            #break if all features dropped in the last step are recovered\n",
    "            bestAUC_recover = 0\n",
    "            score_hist.append(score[0]) #show the trend\n",
    "            with open(('XGBoost_backward_selection_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f3:\n",
    "                pickle.dump(use_features, f3, protocol =2)\n",
    "            with open(('fscores_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f4:\n",
    "                pickle.dump(fscore_temp, f4, protocol =2)\n",
    "                \n",
    "            print('AUC found in this step (%f) is worse than %f in the last step. Recovering features from %d features' %(score[0], bestAUC, len(hist_features)))\n",
    "            for f in range(len(hist_features)):                           \n",
    "                use_features = np.append(use_features, hist_features[f])\n",
    "                score, fscore_temp = cv_loop(Xtrain[userows, :][:,use_features], ytrain[userows], MODEL, N=n_cv_rounds)\n",
    "                score_hist.append(score[0])\n",
    "                if round(score[0] * auc_prec2) >= round(bestAUC * auc_prec2):\n",
    "                    if round(score[0] * auc_prec2) >= round(bestAUC_recover * auc_prec2):\n",
    "                        bestAUC_recover = score[0] #found it, but let's keep improving.\n",
    "                    else:\n",
    "                        break;#found it. And we cannot do better. \n",
    "                \n",
    "            bestAUC = score[0] #or all the hist_features are included \n",
    "            #save results\n",
    "            str1=time.strftime(\"%b%d%Y_%H%M%S\", time.localtime())\n",
    "            with open(('XGBoost_backward_selection_' + str(len(use_features)) +'Features '+str1 + '_AUC_' + '0p'+ str(int(bestAUC*1e5))  +'.p'), 'wb') as f5:\n",
    "                pickle.dump(use_features, f5, protocol =2)\n",
    "            \n",
    "            print('All good hist_features recovered, no more selection is necessary.')\n",
    "            print('Final best AUC is %f' % bestAUC)\n",
    "            break #the while loop           \n",
    "            \n",
    "    if diagonistics:\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(score_hist)),score_hist,'ro--')\n",
    "        plt.xlabel('Feature selection step')\n",
    "        plt.ylabel('AUC score')\n",
    "        plt.title('Feature-selection curve')\n",
    "        plt.savefig('plots/featsel_curve.png')\n",
    "    \n",
    "    print('Feature selection done: %d features selected'%len(use_features))\n",
    "    \n",
    "    return use_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XGBoostClassifier():\n",
    "    def __init__(self, num_boost_round=10, **params):\n",
    "        self.clf = None\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.params = params\n",
    "        self.params.update({'objective': 'binary:logistic'})\n",
    " \n",
    "    def fit(self, X, y, num_boost_round=None):\n",
    "        num_boost_round = num_boost_round or self.num_boost_round\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        self.clf = xgb.train(params=self.params, dtrain=dtrain, num_boost_round=num_boost_round)\n",
    "        self.fscore = self.clf.get_fscore()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        num2label = {i: label for label, i in self.label2num.items()}\n",
    "        Y = self.predict_proba(X)\n",
    "        y = np.argmax(Y, axis=1)\n",
    "        return np.array([num2label[i] for i in y])\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        return self.clf.predict(dtest)\n",
    " \n",
    "    def score(self, X, y):\n",
    "        Y = self.predict_proba(X)\n",
    "        return 1 / self.logloss(y, Y)\n",
    " \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    " \n",
    "    def set_params(self, **params):\n",
    "        if 'num_boost_round' in params:\n",
    "            self.num_boost_round = params.pop('num_boost_round')\n",
    "        if 'objective' in params:\n",
    "            del params['objective']\n",
    "        self.params.update(params)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def logloss(self,y_true, Y_pred):\n",
    "        label2num = dict((name, i) for i, name in enumerate(sorted(set(y_true))))\n",
    "        return -1 * sum(math.log(y[label2num[label]]) if y[label2num[label]] > 0 else -np.inf \\\n",
    "                        for y, label in zip(Y_pred, y_true)) / len(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbclassifier = XGBoostClassifier(num_boost_round=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'max_depth':14, \n",
    "             'eta':0.01, \n",
    "             'objective':'binary:logistic', \n",
    "             'subsample':0.6,\n",
    "             'colsample_bytree':0.6,\n",
    "             'eval_metric': 'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing backward feature selection...\n",
      "\t\t\t\t 1762 features left. Current AUC: 0.772257\n",
      "\t\t\t\t 1409 features left. Current AUC: 0.772358\n",
      "\t\t\t\t 1127 features left. Current AUC: 0.772297\n",
      "\t\t\t\t 901 features left. Current AUC: 0.772328\n",
      "\t\t\t\t 720 features left. Current AUC: 0.772457\n",
      "\t\t\t\t 576 features left. Current AUC: 0.772327\n",
      "AUC found in this step (0.771375) is worse than 0.772327 in the last step. Recovering features from 116 features\n",
      "All good hist_features recovered, no more selection is necessary.\n",
      "Final best AUC is 0.772285\n",
      "Feature selection done: 487 features selected\n",
      "Time elapsed = 163.514066668\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEZCAYAAABb3GilAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8Z0FF2OMMb77fwKBz3D0hA4mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fdf7ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tic_total = time.time()\n",
    "features=feature_selection_backward(xgbclassifier, params, X, y, diagonistics=True, SEED=42, num_rows=X.shape[0], drop_features_percent=0.2, feature_num_thresh=10, n_cv_rounds=5, auc_prec=1000, auc_prec2=10000)\n",
    "elapsed_total = time.time() - tic_total\n",
    "print ('Time elapsed = {}'.format(elapsed_total/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
